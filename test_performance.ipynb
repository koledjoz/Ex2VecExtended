{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f84fed-eb0a-4363-9b3e-80243e4cfd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets import Ex2VecOriginalDatasetShared, GLOBAL_SHARED_DATA, Ex2VecOriginalDatasetWrap\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import psutil\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3995a5eb-5951-4228-84e8-e254c089b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4892757/4892757 [00:47<00:00, 102172.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 4892757/4892757 [00:48<00:00, 99855.73it/s]\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_SHARED_DATA['train'] = Ex2VecOriginalDatasetShared('sorted_data.parquet', 'train_dict.json', 'interactions.h5', sample_negative=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c61fcc7-8da4-4a1c-bf7b-3c98f3d67835",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Ex2VecOriginalDatasetWrap(dataset_id='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b54fd3-7542-4aaa-b0f7-c5c6a91d499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Remove None entries\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    \n",
    "    if not batch:\n",
    "        return None  # Signal to skip this batch\n",
    "    \n",
    "    # Stack each field in the batch\n",
    "    collated_batch = {}\n",
    "    keys = batch[0].keys()\n",
    "    for key in keys:\n",
    "        collated_batch[key] = torch.stack([sample[key] for sample in batch])\n",
    "\n",
    "    return collated_batch\n",
    "\n",
    "def print_memory(label=\"\"):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / (1024 ** 2)\n",
    "    print(f\"[{label}] Memory: {mem:.2f} MB\")\n",
    "    return mem\n",
    "\n",
    "def print_total_memory(label=\"\"):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss\n",
    "    total = mem\n",
    "\n",
    "    # Add memory of all child processes (DataLoader workers)\n",
    "    for child in process.children(recursive=True):\n",
    "        try:\n",
    "            total += child.memory_info().rss\n",
    "        except psutil.NoSuchProcess:\n",
    "            pass  # Process may have exited\n",
    "\n",
    "    print(f\"[{label}] Total memory incl. workers: {total / (1024 ** 2):.2f} MB\")\n",
    "    return total\n",
    "\n",
    "def run_test(num_workers):\n",
    "    print(f\"\\n== Running with {num_workers} workers ==\")\n",
    "    dataset = Ex2VecOriginalDatasetWrap(dataset_id='train')\n",
    "    loader = DataLoader(dataset, batch_size=1, num_workers=num_workers, collate_fn=collate_fn)\n",
    "\n",
    "    print_total_memory(\"Before loading\")\n",
    "\n",
    "    # Trigger worker start and one batch load\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i > 1:\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print_total_memory(\"After loading\")\n",
    "    del loader\n",
    "    time.sleep(1)  # give OS time to clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4fcc0c-6963-493e-8c00-3e73f72404ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running with 0 workers ==\n",
      "[Before loading] Total memory incl. workers: 3269.45 MB\n",
      "[After loading] Total memory incl. workers: 3273.58 MB\n",
      "\n",
      "== Running with 1 workers ==\n",
      "[Before loading] Total memory incl. workers: 3273.58 MB\n",
      "[After loading] Total memory incl. workers: 3265.57 MB\n",
      "\n",
      "== Running with 2 workers ==\n",
      "[Before loading] Total memory incl. workers: 3265.57 MB\n",
      "[After loading] Total memory incl. workers: 3265.59 MB\n",
      "\n",
      "== Running with 4 workers ==\n",
      "[Before loading] Total memory incl. workers: 3265.59 MB\n",
      "[After loading] Total memory incl. workers: 3265.64 MB\n",
      "\n",
      "== Running with 8 workers ==\n",
      "[Before loading] Total memory incl. workers: 3265.64 MB\n",
      "[After loading] Total memory incl. workers: 3265.73 MB\n",
      "\n",
      "== Running with 10 workers ==\n",
      "[Before loading] Total memory incl. workers: 3265.95 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/z/Skola/ING/Recommenders/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After loading] Total memory incl. workers: 3266.13 MB\n",
      "\n",
      "== Running with 12 workers ==\n",
      "[Before loading] Total memory incl. workers: 3266.13 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/z/Skola/ING/Recommenders/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After loading] Total memory incl. workers: 3266.19 MB\n",
      "\n",
      "== Running with 14 workers ==\n",
      "[Before loading] Total memory incl. workers: 3266.19 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/z/Skola/ING/Recommenders/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 14 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After loading] Total memory incl. workers: 3266.25 MB\n",
      "\n",
      "== Running with 16 workers ==\n",
      "[Before loading] Total memory incl. workers: 3266.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/z/Skola/ING/Recommenders/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After loading] Total memory incl. workers: 3266.34 MB\n"
     ]
    }
   ],
   "source": [
    "for workers in [0, 1, 2, 4, 8, 10, 12, 14, 16]:\n",
    "    run_test(workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
